VPS:
brew install multipass
ssh-keygen -C username -f multipass-ssh-key
* edit cloud-init.yaml with your values
multipass launch -n your_vm_name --cloud-init cloud-init.yaml

Starting Flask Application with VPS:
ssh username@vm_ip_addr_here -i multipass-ssh-key -o StrictHostKeyChecking=no
sudo apt install nginx
sudo apt install gunicorn3
* transfer code files to vm's appropriate locations
sudo systemctl daemon-reload
sudo systemctl enable service_script_name
sudo systemctl start/stop/status service_script_name

Installing Dependencies:
sudo apt install python3-pip
pip3 install -r requirements.txt























<< Research Area >>
- The smallest element of an image is called a pixel
- Each pixel is represented numerically through RGB or grayscale
- In the grayscale model, each pixel holds a single value representing
  the amount/intesity of light
- Features of an image are derived from pixel patterns, such as edges,
  corners and shapes. 
- When we have a large collection of these features, we can
  begin to identify things and solve tasks.
- Dark regions will have a smaller pixel sum than lighter regions
- There are 4 Haar-like features:
  a) 2 vertical rectangles (edges)
  b) 2 horizontal rectangles (edges)
  c) A centered rectangle (lines)
  d) Diagonal feature with 4 rectangles (diagonals)
- Integral images are used to efficiently calculate the sum
  of pixels in an area
- Boosting is a machine learning algorithm where classifiers
  that perform well are given greater consideration/importance or 
  a higher weight. 

Viola-Jones General Object Detection Framework:
1. Select Haar-like features
2. Create an intergral image
3. Run AdaBoost Training
4. Create classifier cascades

Process:
1) start at top left of picture and move in blocks
2) run classifier tests on each block to identify
3) to increase efficiency, we create cascades which
   are stages of tests that increase with precision
   (a block must pass all stages)
 
Note: A cascade are a collection of XML files containing
      opencv data. You initialize the code to the cascade
      you want and it does all the detection work. It is
      basically telling OpenCV what to look for in images.

Clarifying the Difference between Haar Cascades and Convolutional Neural Nets:
Haar cascades are mostly for the detection of eyes, face, body. Its more of machine learning concept and not very accurate.
CNN or convolutional neural nets are newer and a deep learning approach which can take in an input image, 
assign importance (learnable weights and biases) to various aspects/objects in the image, and be able to differentiate
one from the other. CNN are more accurate and more tools have already been built to form them. (i.e. Teachable Machine)

Local Binary Pattern (we can code this ourselves later, for now we use the OpenCV implementation):
- LBPH an operator which labels the pixels of an image as a binary number based on neighbouring pixels
- The operator is determined by two measures: local spatial patterns and grayscale contrast
- Looks at 9 pixels at a time and turns it into a single value
- Start by comparing the central pixel with the neighbouring pixels grayscale value
- If the neighbouring pixel is greater than or equal to the central pixel assign 1 to the neighbouring pixel, else assign 0
- Combine assigned values of the 8 neighbouring pixels together to generate a binary number in any ordering which corresponds to a decimal number for the central pixel, do this for every pixel but with consistent order
- This is good because if the lighting is different, for example, while the values on the grayscale will differ, their relative differences will be the same 
- We can also detect edges with this process. When we transition from a 0 to 1, there is an edge.
- When we have enough decimal values we can combine this with a histogram to measure the frequency of each value
- To start, we divide the resulting LBP image into grids (let's say we split it into an 8 x 8 grid) and create a histogram for each grid
- The possible values for each pixel after LBP is still 0 to 255, so for each grid we will have 256 positions for the histogram
- Then, we concatenate all the histograms for each grid to represent our image and process it for recognition (in our case, our histogram should have 8 x 8 x 256 positions in the final histogram)
- To compare the 2 images, we compare their corresponding histograms using a simple euclidean distance calculation outlined below
hist1 = [... LBP values ...]
hist2 = [... LBP values ...]
dist = 0
for i in range(len(hist1)):
  dist += pow(hist1[i] - hist2[i])
dist = sqrt(dist)
- The closest histogram wins and also the distance can be used as a "confidence measurement"
- We can then define a threshold for which the confidence measurement must reach and if it is reached, we have successfully recognized a face

VGG16 Convolutional Neraul Network by Keras:
VGG16 is a CNN thatâ€™s used for image recognition. It utilizes 16 layers with weights and is 
considered one of the best vision model architectures to date. 



